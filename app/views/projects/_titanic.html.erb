<p class="firstParagraph">The Titanic shipwreck led to the death of 1502 out of 2224 passengers in 1912. One of the reasons of such loss of life was the insufficient supply of lifeboats. This project predicts what sort of people are likely to survive.</p>

<h3>0. Data</h3>
The data contains the following variables:
<pre class="dataPre">
survival        Survival (0 = No; 1 = Yes)
pclass          Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)
name            Name
sex             Sex
age             Age
sibsp           Number of Siblings/Spouses Aboard
parch           Number of Parents/Children Aboard
ticket          Ticket Number
fare            Passenger Fare
cabin           Cabin
embarked        Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)
</pre>

The data looks like this:

<table class="table table-bordered table-hover table-condensed">
  <thead>
      <tr>
        <th>survived</th>
        <th>pclass</th>
        <th>name</th>
        <th>sex</th>
        <th>age</th>
        <th>sibsp</th>
        <th>parch</th>
        <th>ticket</th>
        <th>fare</th>
        <th>cabin</th>
        <th>embarked</th>
      </tr>
  </thead>
  <tbody>
      <tr>
        <td>0</td>
        <td>3</td>
        <td>Braund, Mr. Owen Harris</td>
        <td>male</td>
        <td>22</td>
        <td>1</td>
        <td>0</td>
        <td>A/5 21171</td>
        <td>7.25</td>
        <td></td>
        <td>S</td>
      </tr>
      <tr>
        <td>0</td>
        <td>1</td>
        <td>Van der hoef, Mr. Wyckoff</td>
        <td>male</td>
        <td>61</td>
        <td>0</td>
        <td>0</td>
        <td>111240</td>
        <td>33.5</td>
        <td>B19</td>
        <td>S</td>
      </tr>
      <tr>
        <td>1</td>
        <td>2</td>
        <td>Watt, Mrs. James (Elizabeth "Bessie" Inglis Milne)</td>
        <td>female</td>
        <td>40</td>
        <td>0</td>
        <td>0</td>
        <td>C.A. 33595</td>
        <td>15.75</td>
        <td></td>
        <td>S</td>
      </tr>
      <tr>
        <td>1</td>
        <td>3</td>
        <td>Goldsmith, Master. Frank John William "Frankie"</td>
        <td>male</td>
        <td>9</td>
        <td>0</td>
        <td>2</td>
        <td>363291</td>
        <td>20.525</td>
        <td>A7</td>
        <td>Q</td>
      </tr>
  </tbody>
</table>

We can see that the data isn't ideal (i.e. ready to be dumped into all major Machine Learning algorithms). For example, there are:
<ul>
  <li>Attributes with missing data (e.g. <i>cabin</i> as shown above). Specifically, the <i>age</i>, <i>cabin</i> and <i>embarked</i> attributes have 177 (19.9%), 687 (77%) and 2 (0.1%) pieces of missing data, respective; for a total of 866 (9.7% overall) missing slots. Now that is a lot of missing data -- it almost renders the <i>cabin</i> attribute too sparse to be useful.</li>
  <li>The <i>name</i> and <i>ticket</i> attributes seem too versatile to be useful.</li>
</ul>
<h4>0.1 Visualizing the Data</h4>

<h3>1. Preliminary Fitting</h3>
Let's ignore the fact that the data isn't pretty and feature selection has yet to be done, and just first fit a model for benchmarking.
<h3>Feature Selection</h3>

<h3>2. Where do we go from here?</h3>

<h3>3. Conclusions</h3>
