<p class="firstParagraph"
   xmlns="http://www.w3.org/1999/html">The Titanic shipwreck led to the death of 1502 out of 2224 passengers in 1912. One of the reasons of such loss of life was the insufficient supply of lifeboats. This project predicts what sort of people are likely to survive. The evaluation criteria is the percentage of correct predictions.</p>
<!------------------------------------------------------------------------------------------------------------------->

<h3>0. Data</h3>
The data contains the following variables:
<pre class="dataPre">
survival        Survival (0 = No; 1 = Yes)
pclass          Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)
name            Name
sex             Sex
age             Age
sibsp           Number of Siblings/Spouses Aboard
parch           Number of Parents/Children Aboard
ticket          Ticket Number
fare            Passenger Fare
cabin           Cabin
embarked        Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)
</pre>

Here's a snippet of the training data:

<table class="table table-bordered table-hover table-condensed">
  <thead>
      <tr>
        <th>survived</th>
        <th>pclass</th>
        <th>name</th>
        <th>sex</th>
        <th>age</th>
        <th>sibsp</th>
        <th>parch</th>
        <th>ticket</th>
        <th>fare</th>
        <th>cabin</th>
        <th>embarked</th>
      </tr>
  </thead>
  <tbody>
      <tr>
        <td>0</td>
        <td>3</td>
        <td>Braund, Mr. Owen Harris</td>
        <td>male</td>
        <td>22</td>
        <td>1</td>
        <td>0</td>
        <td>A/5 21171</td>
        <td>7.25</td>
        <td></td>
        <td>S</td>
      </tr>
      <tr>
        <td>0</td>
        <td>1</td>
        <td>Van der hoef, Mr. Wyckoff</td>
        <td>male</td>
        <td>61</td>
        <td>0</td>
        <td>0</td>
        <td>111240</td>
        <td>33.5</td>
        <td>B19</td>
        <td>S</td>
      </tr>
      <tr>
        <td>1</td>
        <td>2</td>
        <td>Watt, Mrs. James (Elizabeth "Bessie" Inglis Milne)</td>
        <td>female</td>
        <td>40</td>
        <td>0</td>
        <td>0</td>
        <td>C.A. 33595</td>
        <td>15.75</td>
        <td></td>
        <td>S</td>
      </tr>
      <tr>
        <td>1</td>
        <td>3</td>
        <td>Goldsmith, Master. Frank John William "Frankie"</td>
        <td>male</td>
        <td>9</td>
        <td>0</td>
        <td>2</td>
        <td>363291</td>
        <td>20.525</td>
        <td>A7</td>
        <td>Q</td>
      </tr>
  </tbody>
</table>

The goal is to predict <i>survival</i> given the rest of the variables as input. The training data consists of 892 records and 419 predictions are to be made given their respective input variables.

We can see that the data isn't ideal (i.e. ready to be dumped into all major Machine Learning algorithms). For example, there are:
<ul>
  <li>Attributes with missing data (e.g. <i>cabin</i> as shown above). Specifically, the <i>age</i>, <i>cabin</i> and <i>embarked</i> attributes have 177 (19.9%), 687 (77%) and 2 (0.1%) pieces of missing data, respective; for a total of 866 (9.7% overall) missing slots. Now that is a lot of missing data -- it almost renders the <i>cabin</i> attribute too sparse to be useful.</li>
  <li>The <i>name</i>, <i>cabin</i> and <i>ticket</i> attributes seem too versatile to be useful.</li>
</ul>

<h4>0.1 Data Modification</h4>
Some data fields need to be mangled before they can be plugged into machine learning algorithms.
<ul>
  <li>
    <i>Name</i> is too important to be omitted. So what useful information can we extract from it? The title -- Master, Mr, Mrs, Miss, etc. It provides important information about an individual's social status, marital status, gender and vaguely the age. It is especially helpful when <i>age</i> and <i>sex</i> fields have missing data.
  </li>
  <li>
    <i>Cabin</i> comes in the format of "C85", "A6", "B78", etc. The first letter, which represents the main cabin section, is preserved; the numbers are omitted.
  </li>
  <li>
    <i>Ticket</i> is difficult to work with because it consists of a wide range of letters and numbers, e.g. "STON/O2. 3101282", "17463", "PC 17601", etc. The letters are kept. The numbers are discretized by preserving the first digit and the number of digits, e.g. "17463" becomes "1_5".
  </li>
  <li>
    Missing data could be filled by the average or the mode of the available data, or simply a fixed value. As we'll see in a later section, determining how missing data should be filled is in fact part of the parameters-tuning process. In addition, <i>age</i> is so important that we fill missing values with linear SVM predictions made using the other fields.
  </li>
</ul>

<!------------------------------------------------------------------------------------------------------------------->
<h4>0.2 Data Visualization</h4>
<div>The plots below demonstrate a feature's distribution as well as how it affects survival (<%= render :partial => 'projects/titanic/deadAlive' %>). In each subplot:
  <ul>
    <li>The (stacked) histograms represent the number of survivals and deaths. </li>
    <li>X-axis represents a feature's values.</li>
    <li>The left Y-axis scale represents frequencies, and the right Y-axis scale represents the probability of survival.</li>
    <li>The middle line (or dot in some cases) represents the probability of survival. Whereas the bands represent the confidence intervals of the probability of survival.</li>
  </ul>
</div>

<%= image_tag 'titanic/distributions.png' %>

<div>We can see from the distribution plots (above) that:
  <ul>
    <li>Females are more likely to survive (upper-left).</li>
    <li>The probability of survival decreases with age, especially dips for individuals in their 20s~30s. (upper-right)</li>
    <li>The more expensive the fare, the better the chance of surviving. Similarly, upper-class passengers were more likely to survive. (middle)</li>
    <li>Men, who were not Masters, had low probability of survival. (lower-left)</li>
    <li>Passengers with 1 or 2 siblings were more likely to survive than others who did not.</li>
  </ul>
</div>
<!------------------------------------------------------------------------------------------------------------------->

<h4>0.3 Feature Importance</h4>
<p>Since there are only 10 fields, feature selection is unnecessary. However, it is still interesting and useful to know which features are more important.</p>
<p>First rank the attributes according to their Random Forest (100 trees) importance, linear SVM weights, Information Gain, Gain Ratio, and Gini index, sorted by Random Forest importance (shown in table below).</p>
<table class="table table-bordered table-hover table-condensed">
  <thead>
  <tr>
    <td>Attribute</td>
    <td>RF</td>
    <td>SVM</td>
    <td>Inf. Gain</td>
    <td>Gain Ratio</td>
    <td>Gini</td>
  </tr>
  </thead>
  <tbody>
  <tr>
    <td>sex</td>
    <td>0.242</td>
    <td>1.402</td>
    <td>0.218</td>
    <td>0.232</td>
    <td>0.070</td>
  </tr>
  <tr>
    <td>age</td>
    <td>0.179</td>
    <td>0.432</td>
    <td>0.016</td>
    <td>0.005</td>
    <td>0.005</td>
  </tr>
  <tr>
    <td>fare</td>
    <td>0.153</td>
    <td>0.192</td>
    <td>0.099</td>
    <td>0.030</td>
    <td>0.031</td>
  </tr>
  <tr>
    <td>pclass</td>
    <td>0.090</td>
    <td>0.139</td>
    <td>0.084</td>
    <td>0.058</td>
    <td>0.027</td>
  </tr>
  <tr>
    <td>name</td>
    <td>0.084</td>
    <td>0.269</td>
    <td>0.239</td>
    <td>0.144</td>
    <td>0.075</td>
  </tr>
  <tr>
    <td>ticket</td>
    <td>0.080</td>
    <td>0.179</td>
    <td>0.147</td>
    <td>0.037</td>
    <td>0.043</td>
  </tr>
  <tr>
    <td>cabin</td>
    <td>0.064</td>
    <td>0.032</td>
    <td>0.022</td>
    <td>0.009</td>
    <td>0.007</td>
  </tr>
  <tr>
    <td>sibsp</td>
    <td>0.050</td>
    <td>0.362</td>
    <td>0.033</td>
    <td>0.025</td>
    <td>0.010</td>
  </tr>
  <tr>
    <td>embarked</td>
    <td>0.030</td>
    <td>0.006</td>
    <td>0.021</td>
    <td>0.019</td>
    <td>0.007</td>
  </tr>
  <tr>
    <td>parch</td>
    <td>0.030</td>
    <td>0.257</td>
    <td>0.024</td>
    <td>0.021</td>
    <td>0.007</td>
  </tr>
  </tbody>
</table>
<p>Below is a plot of average feature importances with their respective standard deviations calculated from a random forest with 100 trees.</p>
<%= image_tag 'titanic/feature_importances.png' %>
<p>This bolsters our belief from the previous section -- <i>sex, age</i> and <i>fare</i> have the strongest relationship with survival.</p>

<div>Note the <i>survey plot</i> A survey plot is a simple multi-attribute visualization technique that can help to spot correlations between any two variables especially when the data is sorted according to a particular dimension. Each horizontal splice in a plot corresponds to a particular data instance. The data on a specific attribute is shown in a single column, where the length of the line corresponds to the dimensional value. When data includes a discrete or continuous class, the slices (data instances) are colored correspondingly. Therefore, if a slice only has one color (again <%= render :partial => 'projects/titanic/deadAlive' %>) when a feature is sorted, then there's a discernible monotonic relationship between this feature and the outcome. The survey plot (below) is sorted by <i>sex, fare</i> and <i>age</i> in that order. We could see that <i>sex</i> alone is enough to predict that most females have survived (the lower slice). On the other hand, it's complicated in the case of males. After further splitting by fare and age, the monotonic relationship is somewhat stronger, since each slice of age (upside-down trapezoid) has mostly just one color. In summary, the survey plot tells us that:
  <ul>
    <li>Since there's a strong relationship between being female and having survived, a simple and robust model should be used for females.</li>
    <li>Since there's no strong or discernible (at least monotonic) relationship between the features and survival for males, a complex, possibly non-linear model (e.g. SVM with a non-linear kernel) should be used for males.</li>
  </ul>
</div>
<%= image_tag 'titanic/survey.PNG' %>
<!------------------------------------------------------------------------------------------------------------------->

<h3>1. Fitting Models</h3>
Alright, let the fun begin!

<h4>1.0 Preliminary Fitting</h4>
<p>Let's first fit a handful of base models for benchmarking purposes. Tree-based algorithms are capable of dealing with missing data. For other algorithms, missing data is replaced with the average of that variable. In addition, all variables are normalized. (Note: in a later section we tune the process to find out which data preprocessing method is optimal.)
</p>
<!------------------------------------------------------------------------------------------------------------------->

<h4>1.1 Ensemble Methods</h4>
<!------------------------------------------------------------------------------------------------------------------->

<h4>1.2 Tuning </h4>
<!------------------------------------------------------------------------------------------------------------------->

<h3>2. Where do we go from here?</h3>
<!------------------------------------------------------------------------------------------------------------------->

<h3>3. Conclusions</h3>
